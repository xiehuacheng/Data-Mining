{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dgl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_path, edge_path):\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    edge_df = pd.read_csv(edge_path, encoding='utf-8')\n",
    "\n",
    "    # 初始化字典和计数器\n",
    "    geohash_df_dict = {}\n",
    "    date_df_dict = {}\n",
    "    number_hash = 0\n",
    "    number_date = 0\n",
    "\n",
    "    # 为geohash_id创建映射\n",
    "    for i in df[\"geohash_id\"]:\n",
    "        if i not in geohash_df_dict.keys():\n",
    "            geohash_df_dict[i] = number_hash\n",
    "            number_hash += 1\n",
    "\n",
    "    # 为date_id创建映射\n",
    "    for i in df[\"date_id\"]:\n",
    "        if i not in date_df_dict.keys():\n",
    "            date_df_dict[i] = number_date\n",
    "            number_date += 1\n",
    "        \n",
    "    # 将geohash_id和date_id替换为映射后的值\n",
    "    df[\"geohash_id\"] = df[\"geohash_id\"].map(geohash_df_dict)\n",
    "    df[\"date_id\"] = df[\"date_id\"].map(date_df_dict)\n",
    "    edge_df[\"geohash6_point1\"] = edge_df[\"geohash6_point1\"].map(geohash_df_dict)\n",
    "    edge_df[\"geohash6_point2\"] = edge_df[\"geohash6_point2\"].map(geohash_df_dict)\n",
    "    edge_df[\"date_id\"] = edge_df[\"date_id\"].map(date_df_dict)\n",
    "    \n",
    "    # 去除为NaN的行\n",
    "    df = df.dropna()\n",
    "    edge_df = edge_df.dropna()\n",
    "    \n",
    "    # 将edge_df中的geohash6_point1和geohash6_point2列的数据转换为int64\n",
    "    edge_df[\"geohash6_point1\"] = edge_df[\"geohash6_point1\"].astype(\"int64\")\n",
    "    edge_df[\"geohash6_point2\"] = edge_df[\"geohash6_point2\"].astype(\"int64\")\n",
    "    \n",
    "    return df, edge_df, geohash_df_dict, number_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data(file_path, edge_path, pre_geohash_df_dict, pre_number_date):\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    edge_df = pd.read_csv(edge_path, encoding='utf-8')\n",
    "\n",
    "    # 初始化字典和计数器\n",
    "    geohash_df_dict = pre_geohash_df_dict\n",
    "    date_df_dict = {}\n",
    "    number_date = pre_number_date\n",
    "\n",
    "    # 为date_id创建映射\n",
    "    for i in df[\"date_id\"]:\n",
    "        if i not in date_df_dict.keys():\n",
    "            date_df_dict[i] = number_date\n",
    "            number_date += 1\n",
    "        \n",
    "    # 将geohash_id和date_id替换为映射后的值\n",
    "    df[\"geohash_id\"] = df[\"geohash_id\"].map(geohash_df_dict)\n",
    "    df[\"date_id\"] = df[\"date_id\"].map(date_df_dict)\n",
    "    edge_df[\"geohash6_point1\"] = edge_df[\"geohash6_point1\"].map(geohash_df_dict)\n",
    "    edge_df[\"geohash6_point2\"] = edge_df[\"geohash6_point2\"].map(geohash_df_dict)\n",
    "    edge_df[\"date_id\"] = edge_df[\"date_id\"].map(date_df_dict)\n",
    "    \n",
    "    # 去除为NaN的行\n",
    "    df = df.dropna()\n",
    "    edge_df = edge_df.dropna()\n",
    "    \n",
    "    # 将edge_df中的geohash6_point1和geohash6_point2列的数据转换为int64\n",
    "    edge_df[\"geohash6_point1\"] = edge_df[\"geohash6_point1\"].astype(\"int64\")\n",
    "    edge_df[\"geohash6_point2\"] = edge_df[\"geohash6_point2\"].astype(\"int64\")\n",
    "    \n",
    "    return df, edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "train_node_data, train_edge_data, geohash_df_dict, number_date = process_data('data/train_90.csv', 'data/edge_90.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试数据\n",
    "test_node_data, test_edge_data = process_test_data('data/node_test_4_A.csv', 'data/edge_test_4_A.csv', geohash_df_dict, number_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除train_node_data中全为0的列\n",
    "train_node_data = train_node_data.loc[:, (train_node_data != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除test_node_data中全为0的列\n",
    "test_node_data = test_node_data.loc[:, (test_node_data != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置node_id，用于后续的LSTM输入，从0到1139，类型为float32\n",
    "train_node_id = torch.arange(0, 1140, dtype=torch.float32)\n",
    "# 为节点添加两个为0的特征\n",
    "train_temp = torch.zeros((90, 1140, 2), dtype=torch.float32)\n",
    "# 遍历每一条边将边上的特征作为节点特征累加到对应的节点上的'Edge_F_1&2'中\n",
    "for i, row in train_edge_data.iterrows():\n",
    "    # 从edge_data中取出边的两个端点\n",
    "    point1 = row['geohash6_point1']\n",
    "    point2 = row['geohash6_point2']\n",
    "    # 从edge_data中取出日期\n",
    "    date = row['date_id']\n",
    "    # 从edge_data中取出边上的特征\n",
    "    feature1 = row['F_1']\n",
    "    feature2 = row['F_2']\n",
    "    \n",
    "    train_temp[date][point1][0] += feature1\n",
    "    train_temp[date][point1][1] += feature2\n",
    "    train_temp[date][point2][0] += feature1\n",
    "    train_temp[date][point2][1] += feature2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置node_id，用于后续的LSTM输入，从0到1139，类型为float32\n",
    "test_node_id = torch.arange(0, 1140, dtype=torch.float32)\n",
    "# 为节点添加两个为0的特征\n",
    "test_temp = torch.zeros((4, 1140, 2), dtype=torch.float32)\n",
    "# 遍历每一条边将边上的特征作为节点特征累加到对应的节点上的'Edge_F_1&2'中\n",
    "for i, row in test_edge_data.iterrows():\n",
    "    # 从edge_data中取出边的两个端点\n",
    "    point1 = row['geohash6_point1']\n",
    "    point2 = row['geohash6_point2']\n",
    "    # 从edge_data中取出日期\n",
    "    date = row['date_id']\n",
    "    # 从edge_data中取出边上的特征\n",
    "    feature1 = row['F_1']\n",
    "    feature2 = row['F_2']\n",
    "    \n",
    "    test_temp[date - 90][point1][0] += feature1\n",
    "    test_temp[date - 90][point1][1] += feature2\n",
    "    test_temp[date - 90][point2][0] += feature1\n",
    "    test_temp[date - 90][point2][1] += feature2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对node_data的第三列到第三十五列进行标准化\n",
    "train_node_data.iloc[:, 2:35] = (train_node_data.iloc[:, 2:35] - train_node_data.iloc[:, 2:35].mean()) / train_node_data.iloc[:, 2:35].std()\n",
    "\n",
    "# 对edge_data的第三列到第四列进行标准化\n",
    "train_edge_data.iloc[:, 2:4] = (train_edge_data.iloc[:, 2:4] - train_edge_data.iloc[:, 2:4].mean()) / train_edge_data.iloc[:, 2:4].std()\n",
    "\n",
    "# 对temp进行标准化\n",
    "train_temp = (train_temp - train_temp.mean()) / train_temp.std()\n",
    "\n",
    "# 打印node_data的前5行\n",
    "print(train_node_data.head())\n",
    "\n",
    "# 打印edge_data的前5行\n",
    "print(train_edge_data.head())\n",
    "\n",
    "# 打印temp的前5行\n",
    "print(train_temp[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对node_data的第三列到第三十五列进行标准化\n",
    "test_node_data.iloc[:, 2:35] = (test_node_data.iloc[:, 2:35] - test_node_data.iloc[:, 2:35].mean()) / test_node_data.iloc[:, 2:35].std()\n",
    "\n",
    "# 对edge_data的第三列到第四列进行标准化\n",
    "test_edge_data.iloc[:, 2:4] = (test_edge_data.iloc[:, 2:4] - test_edge_data.iloc[:, 2:4].mean()) / test_edge_data.iloc[:, 2:4].std()\n",
    "\n",
    "# 对temp进行标准化\n",
    "test_temp = (test_temp - test_temp.mean()) / test_temp.std()\n",
    "\n",
    "# 打印node_data的前5行\n",
    "print(test_node_data.head())\n",
    "\n",
    "# 打印edge_data的前5行\n",
    "print(test_edge_data.head())\n",
    "\n",
    "# 打印temp的前5行\n",
    "print(test_temp[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 对node_data的第三列到第三十五列加入噪声\n",
    "# train_node_data.iloc[:, 2:35] = train_node_data.iloc[:, 2:35].values + torch.randn(train_node_data.shape[0], 33).numpy() * 0.01\n",
    "\n",
    "# # 对edge_data的第三列到第四列加入噪声\n",
    "# train_edge_data.iloc[:, 2:4] = train_edge_data.iloc[:, 2:4].values + torch.randn(train_edge_data.shape[0], 2).numpy() * 0.01\n",
    "\n",
    "# # 对temp加入噪声\n",
    "# train_temp = train_temp + torch.randn(train_temp.shape[0], 1140, 2).numpy() * 0.01\n",
    "\n",
    "# # 打印node_data的前5行\n",
    "# print(train_node_data.head())\n",
    "\n",
    "# # 打印edge_data的前5行\n",
    "# print(train_edge_data.head())\n",
    "\n",
    "# # 打印temp的前5行\n",
    "# print(train_temp[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为node_data加入7个独热编码特征，分别为星期一到星期日\n",
    "train_node_data['Monday'] = 0\n",
    "train_node_data['Tuesday'] = 0\n",
    "train_node_data['Wednesday'] = 0\n",
    "train_node_data['Thursday'] = 0\n",
    "train_node_data['Friday'] = 0\n",
    "train_node_data['Saturday'] = 0\n",
    "train_node_data['Sunday'] = 0\n",
    "\n",
    "# 根据date_id为node_data的独热编码特征赋值\n",
    "for i, row in train_node_data.iterrows():\n",
    "    if row['date_id'] % 7 == 5:\n",
    "        train_node_data.loc[i, 'Monday'] = 1\n",
    "    elif row['date_id'] % 7 == 6:\n",
    "        train_node_data.loc[i, 'Tuesday'] = 1\n",
    "    elif row['date_id'] % 7 == 0:\n",
    "        train_node_data.loc[i, 'Wednesday'] = 1\n",
    "    elif row['date_id'] % 7 == 1:\n",
    "        train_node_data.loc[i, 'Thursday'] = 1\n",
    "    elif row['date_id'] % 7 == 2:\n",
    "        train_node_data.loc[i, 'Friday'] = 1\n",
    "    elif row['date_id'] % 7 == 3:\n",
    "        train_node_data.loc[i, 'Saturday'] = 1\n",
    "    elif row['date_id'] % 7 == 4:\n",
    "        train_node_data.loc[i, 'Sunday'] = 1\n",
    "\n",
    "# 为node_data加入1个独热编码特征，表示是否为节假日\n",
    "train_node_data['Holiday'] = 0\n",
    "\n",
    "# 根据date_id为node_data的独热编码特征赋值\n",
    "holiday_list = [3, 4, 10, 11, 17, 18, 19, 20, 21, 22, 23, 31, 32, 38, 39, 45, 46, 52, 53, 59, 60, 66, 67, 73, 74, 80, 81, 87, 88, 91, 94, 95]\n",
    "\n",
    "for i, row in train_node_data.iterrows():\n",
    "    if row['date_id'] in holiday_list:\n",
    "        train_node_data.loc[i, 'Holiday'] = 1\n",
    "\n",
    "# 打印node_data的前5行\n",
    "print(train_node_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为node_data加入7个独热编码特征，分别为星期一到星期日\n",
    "test_node_data['Monday'] = 0\n",
    "test_node_data['Tuesday'] = 0\n",
    "test_node_data['Wednesday'] = 0\n",
    "test_node_data['Thursday'] = 0\n",
    "test_node_data['Friday'] = 0\n",
    "test_node_data['Saturday'] = 0\n",
    "test_node_data['Sunday'] = 0\n",
    "\n",
    "# 根据date_id为node_data的独热编码特征赋值\n",
    "for i, row in test_node_data.iterrows():\n",
    "    if row['date_id'] % 7 == 5:\n",
    "        test_node_data.loc[i, 'Monday'] = 1\n",
    "    elif row['date_id'] % 7 == 6:\n",
    "        test_node_data.loc[i, 'Tuesday'] = 1\n",
    "    elif row['date_id'] % 7 == 0:\n",
    "        test_node_data.loc[i, 'Wednesday'] = 1\n",
    "    elif row['date_id'] % 7 == 1:\n",
    "        test_node_data.loc[i, 'Thursday'] = 1\n",
    "    elif row['date_id'] % 7 == 2:\n",
    "        test_node_data.loc[i, 'Friday'] = 1\n",
    "    elif row['date_id'] % 7 == 3:\n",
    "        test_node_data.loc[i, 'Saturday'] = 1\n",
    "    elif row['date_id'] % 7 == 4:\n",
    "        test_node_data.loc[i, 'Sunday'] = 1\n",
    "\n",
    "# 为node_data加入1个独热编码特征，表示是否为节假日\n",
    "test_node_data['Holiday'] = 0\n",
    "\n",
    "# 根据date_id为node_data的独热编码特征赋值\n",
    "holiday_list = [3, 4, 10, 11, 17, 18, 19, 20, 21, 22, 23, 31, 32, 38, 39, 45, 46, 52, 53, 59, 60, 66, 67, 73, 74, 80, 81, 87, 88, 91, 94, 95]\n",
    "\n",
    "for i, row in test_node_data.iterrows():\n",
    "    if row['date_id'] in holiday_list:\n",
    "        test_node_data.loc[i, 'Holiday'] = 1\n",
    "\n",
    "# 打印node_data的前5行\n",
    "print(test_node_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据日期对节点和边进行分组\n",
    "train_date_groups = train_node_data.groupby('date_id')\n",
    "train_date_edge_groups = train_edge_data.groupby('date_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据日期对节点和边进行分组\n",
    "test_date_groups = test_node_data.groupby('date_id')\n",
    "test_date_edge_groups = test_edge_data.groupby('date_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一个列表来存储DGL图\n",
    "train_dgl_graphs = []\n",
    "\n",
    "# 对于每个日期，创建一个DGL图\n",
    "for date, group in train_date_groups:\n",
    "    # 获取节点和边的数据\n",
    "    nodes_feature = group.iloc[:, 2:35].values\n",
    "    date_feature = group.iloc[:, 37:].values\n",
    "    nodes_labels = group.iloc[:, 35:37].values\n",
    "    edges_feature = train_date_edge_groups.get_group(date).values\n",
    "    \n",
    "    # 创建DGL图\n",
    "    g = dgl.DGLGraph()\n",
    "    \n",
    "    # 将NumPy数组转换为PyTorch张量并放在与DGL图相同的设备上\n",
    "    nodes_feature = torch.tensor(nodes_feature, device=g.device)\n",
    "    date_feature = torch.tensor(date_feature, device=g.device)\n",
    "    nodes_labels = torch.tensor(nodes_labels, device=g.device)\n",
    "    edges_feature = torch.tensor(edges_feature, device=g.device)\n",
    "    \n",
    "    # 将nodes_feature和temp中的特征拼接起来\n",
    "    nodes_feature = torch.cat([train_temp[date], nodes_feature, date_feature], dim=1)\n",
    "    \n",
    "    # 添加节点\n",
    "    g.add_nodes(nodes_feature.shape[0])\n",
    "    \n",
    "    # 添加正向边和反向边\n",
    "    g.add_edges(edges_feature[:, 0].long(), edges_feature[:, 1].long())\n",
    "    g.add_edges(edges_feature[:, 1].long(), edges_feature[:, 0].long())\n",
    "    \n",
    "    # 添加节点的特征和标签\n",
    "    g.ndata['feat'] = nodes_feature\n",
    "    g.ndata['label'] = nodes_labels\n",
    "    g.ndata['node_id'] = train_node_id\n",
    "    \n",
    "    # 添加正向边和反向边的特征（即将特征按行拼接一次）\n",
    "    g.edata['feat'] = torch.cat([edges_feature[:,2:4], edges_feature[:,2:4]], dim=0)\n",
    "    \n",
    "    # 将图添加到列表中\n",
    "    train_dgl_graphs.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一个列表来存储DGL图\n",
    "test_dgl_graphs = []\n",
    "\n",
    "# 对于每个日期，创建一个DGL图\n",
    "for date, group in test_date_groups:\n",
    "    # 获取节点和边的数据\n",
    "    nodes_feature = group.iloc[:, 2:].values\n",
    "    edges_feature = test_date_edge_groups.get_group(date).values\n",
    "    \n",
    "    # 创建DGL图\n",
    "    g = dgl.DGLGraph()\n",
    "    \n",
    "    # 将NumPy数组转换为PyTorch张量并放在与DGL图相同的设备上\n",
    "    nodes_feature = torch.tensor(nodes_feature, device=g.device)\n",
    "    edges_feature = torch.tensor(edges_feature, device=g.device)\n",
    "    \n",
    "    # 将nodes_feature和temp中的特征拼接起来\n",
    "    nodes_feature = torch.cat([test_temp[date - 90], nodes_feature], dim=1)\n",
    "    \n",
    "    # 添加节点\n",
    "    g.add_nodes(nodes_feature.shape[0])\n",
    "    \n",
    "    # 添加正向边和反向边\n",
    "    g.add_edges(edges_feature[:, 0].long(), edges_feature[:, 1].long())\n",
    "    g.add_edges(edges_feature[:, 1].long(), edges_feature[:, 0].long())\n",
    "    \n",
    "    # 添加节点的特征和标签\n",
    "    g.ndata['feat'] = nodes_feature\n",
    "    g.ndata['node_id'] = test_node_id\n",
    "    \n",
    "    # 添加正向边和反向边的特征（即将特征按行拼接一次）\n",
    "    g.edata['feat'] = torch.cat([edges_feature[:,2:4], edges_feature[:,2:4]], dim=0)\n",
    "    \n",
    "    # 将图添加到列表中\n",
    "    test_dgl_graphs.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回所有创建的DGL图\n",
    "train_dgl_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回所有创建的DGL图\n",
    "test_dgl_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存DGL图\n",
    "dgl.save_graphs('dgl_data/dgl_graphs_train.bin', train_dgl_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存DGL图\n",
    "dgl.save_graphs('dgl_data/dgl_graphs_test.bin', test_dgl_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取DGL图\n",
    "train_dgl_graphs, _ = dgl.load_graphs('dgl_data/dgl_graphs_train.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取DGL图\n",
    "test_dgl_graphs, _ = dgl.load_graphs('dgl_data/dgl_graphs_test.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印第一个DGL图\n",
    "print(train_dgl_graphs[0])\n",
    "print(train_dgl_graphs[0].ndata['feat'][0])\n",
    "print(train_dgl_graphs[0].ndata['label'][0])\n",
    "\n",
    "# 打印第一个DGL图\n",
    "print(test_dgl_graphs[0])\n",
    "print(test_dgl_graphs[0].ndata['feat'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
