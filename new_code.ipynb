{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.cuda\n",
    "import new_model\n",
    "import dgl\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPIPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 辅助动图类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_inline import backend_inline\n",
    "\n",
    "class Animator:\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(7, 5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        backend_inline.set_matplotlib_formats('svg')\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 使用lambda函数捕获参数\n",
    "        self.config_axes = lambda: self.set_axes(xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def set_axes(self, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "        \"\"\"设置matplotlib的轴\"\"\"\n",
    "        self.axes[0].set_xlabel(xlabel)\n",
    "        self.axes[0].set_ylabel(ylabel)\n",
    "        self.axes[0].set_xscale(xscale)\n",
    "        self.axes[0].set_yscale(yscale)\n",
    "        self.axes[0].set_xlim(xlim)\n",
    "        self.axes[0].set_ylim(ylim)\n",
    "        if legend:\n",
    "            self.axes[0].legend(legend)\n",
    "        self.axes[0].grid()\n",
    "\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        plt.pause(0.001)\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "    def show(self):\n",
    "        display.display(self.fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练和评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_eval(train_graph_list, val_graph_list, model, loss_func, num_steps):\n",
    "\n",
    "    eval_loss = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i in range(1, len(val_graph_list)+1):\n",
    "            \n",
    "            if i < num_steps:\n",
    "                batched_graph = dgl.batch(train_graph_list[-(num_steps - i):] + val_graph_list[:i])\n",
    "            else:\n",
    "                batched_graph = dgl.batch(val_graph_list[i - num_steps:i])\n",
    "            \n",
    "            active, consume = model(batched_graph)\n",
    "            label = val_graph_list[i-1].ndata['label']\n",
    "\n",
    "            loss = loss_func(active, label[:, 0].view_as(\n",
    "                active)) + loss_func(consume, label[:, 1].view_as(consume))\n",
    "            \n",
    "            eval_loss.append(loss.item())\n",
    "\n",
    "    model.train()\n",
    "    return sum(eval_loss) / len(eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(train_graph_list, val_graph_list, model, loss_func, num_steps):\n",
    "\n",
    "    eval_loss = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i in range(1, len(val_graph_list)+1):\n",
    "            \n",
    "            if i < num_steps:\n",
    "                batched_graph = dgl.batch(train_graph_list[-(num_steps - i):] + val_graph_list[:i])\n",
    "            else:\n",
    "                batched_graph = dgl.batch(val_graph_list[i - num_steps:i])\n",
    "            \n",
    "            active, consume = model(batched_graph)\n",
    "            label = batched_graph.ndata['label']\n",
    "\n",
    "            loss = loss_func(active, label[:, 0].view_as(\n",
    "                active)) + loss_func(consume, label[:, 1].view_as(consume))\n",
    "            \n",
    "            eval_loss.append(loss.item())\n",
    "\n",
    "    model.train()\n",
    "    return sum(eval_loss) / len(eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_eval(val_data, model, loss_func):\n",
    "    val_loss = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for sequences_data in val_data:\n",
    "            active, consume = model(sequences_data)\n",
    "            \n",
    "            label = sequences_data[-1, :, -2:]\n",
    "\n",
    "            loss = loss_func(active, label[:, 0].view_as(\n",
    "                active)) + loss_func(consume, label[:, 1].view_as(consume))\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "    model.train()\n",
    "    return sum(val_loss) / len(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_time_step_train(graph_list, model, loss_func, optimizer, num_epochs, device, train_ratio, num_steps, threshold):\n",
    "\n",
    "    # 划分训练集和验证集\n",
    "    train_graph_list = graph_list[:int(len(graph_list) * train_ratio)]\n",
    "    val_graph_list = graph_list[int(len(graph_list) * train_ratio):]\n",
    "\n",
    "    # 将数据集放到device上\n",
    "    loss_func = loss_func.to(device)\n",
    "    train_graph_list = [graph.to(device) for graph in train_graph_list]\n",
    "    val_graph_list = [graph.to(device) for graph in val_graph_list]\n",
    "\n",
    "    print('train_length:', len(train_graph_list), 'val_length:', len(val_graph_list))\n",
    "\n",
    "    animator = Animator(xlabel='epoch', ylabel='loss & score', xlim=[0, num_epochs], ylim=[\n",
    "                        0, 50], legend=['train loss', 'val loss', 'score', 'best score'])\n",
    "\n",
    "    # 设置文件夹名称，以日和时分命名\n",
    "    dictionary_name = time.strftime(\"Day%d-Hour%H-Minutes%M\", time.localtime())\n",
    "    \n",
    "    # 如果文件夹不存在则创建文件夹\n",
    "    if not os.path.exists('model/' + dictionary_name):\n",
    "        os.mkdir('model/' + dictionary_name)  \n",
    "\n",
    "    model.train()\n",
    "\n",
    "    best_val_loss = 9999999999\n",
    "    best_score = 0\n",
    "    best_epoch = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    def data(pos):\n",
    "        # 返回从pos位置开始的长度为num_steps的序列\n",
    "        return train_graph_list[pos: pos + num_steps]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = []\n",
    "        \n",
    "        # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n",
    "        sequences = train_graph_list[random.randint(0, num_steps - 1):]\n",
    "        \n",
    "        num_subseqs = len(sequences) // num_steps\n",
    "        \n",
    "        # 长度为num_steps的子序列的起始索引\n",
    "        initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
    "        \n",
    "        # 在随机抽样的迭代过程中，\n",
    "        # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n",
    "        random.shuffle(initial_indices)\n",
    "        \n",
    "        X = [data(j) for j in initial_indices]\n",
    "        \n",
    "        for batch_graph in X:\n",
    "        \n",
    "            # 创建批处理图对象\n",
    "            batched_graph = dgl.batch(batch_graph)\n",
    "            \n",
    "            # 前向传播\n",
    "            active, consume = model(batched_graph)\n",
    "            \n",
    "            # 计算损失\n",
    "            label = batch_graph[-1].ndata['label'].float()\n",
    "            \n",
    "            # print(label.shape)\n",
    "            \n",
    "            loss = loss_func(active, label[:, 0].view_as(\n",
    "                active)) + loss_func(consume, label[:, 1].view_as(consume))\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 计算平均损失\n",
    "        train_loss = sum(train_loss) / len(train_loss)\n",
    "\n",
    "        # 使用评估函数计算验证集上的loss\n",
    "        val_loss = new_eval(train_graph_list, val_graph_list, model, loss_func, num_steps)\n",
    "\n",
    "        # 对val_loss开根号\n",
    "        sqrt_val_loss = torch.sqrt(torch.tensor(val_loss * 4))\n",
    "\n",
    "        # 计算score\n",
    "        score = 1 / (1 + sqrt_val_loss)\n",
    "\n",
    "        # 如果当前模型在验证集上的表现比之前所有模型都好，就保存当前模型的参数\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_score = score\n",
    "            best_epoch = epoch + 1\n",
    "            best_model_state = model.state_dict()\n",
    "            \n",
    "        # 每30个epoch打印一次损失和score\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "\n",
    "            # 打印损失和score\n",
    "            print('Epoch: {0}\\n Train loss: {1}\\n Val loss: {2}\\n Score: {3}\\n Best score: {4}\\n Best val loss: {5}\\n Best epoch: {6}'.format(\n",
    "                epoch + 1, train_loss, val_loss, score, best_score, best_val_loss, best_epoch))\n",
    "\n",
    "            # 绘制动画\n",
    "            animator.add(epoch + 1, (train_loss, val_loss, score * 100, best_score * 100))\n",
    "            \n",
    "        # 每30个epoch保存一次模型，并以epoch和该轮的score命名\n",
    "        if (epoch + 1) % 30 == 0 and score > threshold:\n",
    "            torch.save(model.state_dict(), 'model/' + dictionary_name + '/' + str(epoch + 1) + '-' + \"{:.3f}\".format(score))\n",
    "\n",
    "    return best_model_state, best_score, best_val_loss, best_epoch, dictionary_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_time_step_train_without_eval(graph_list, model, loss_func, optimizer, num_epochs, device, train_ratio, num_steps, threshold):\n",
    "\n",
    "    # 划分训练集和验证集\n",
    "    train_graph_list = graph_list[:int(len(graph_list) * train_ratio)]\n",
    "\n",
    "    # 将数据集放到device上\n",
    "    loss_func = loss_func.to(device)\n",
    "    train_graph_list = [graph.to(device) for graph in train_graph_list]\n",
    "\n",
    "    print('train_length:', len(train_graph_list))\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    def data(pos):\n",
    "        # 返回从pos位置开始的长度为num_steps的序列\n",
    "        return train_graph_list[pos: pos + num_steps]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = []\n",
    "        \n",
    "        # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n",
    "        sequences = train_graph_list[random.randint(0, num_steps - 1):]\n",
    "        \n",
    "        num_subseqs = len(sequences) // num_steps\n",
    "        \n",
    "        # 长度为num_steps的子序列的起始索引\n",
    "        initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
    "        \n",
    "        # 在随机抽样的迭代过程中，\n",
    "        # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n",
    "        random.shuffle(initial_indices)\n",
    "        \n",
    "        X = [data(j) for j in initial_indices]\n",
    "        \n",
    "        for batch_graph in X:\n",
    "        \n",
    "            # 创建批处理图对象\n",
    "            batched_graph = dgl.batch(batch_graph)\n",
    "            \n",
    "            # 前向传播\n",
    "            active, consume = model(batched_graph)\n",
    "            \n",
    "            # print(active[0:5])\n",
    "            # print(consume[0:5])\n",
    "            \n",
    "            # 计算损失\n",
    "            label = batch_graph[-1].ndata['label'].float()\n",
    "            \n",
    "            # print(label[0:5])\n",
    "            \n",
    "            # print(label.shape)\n",
    "            \n",
    "            loss = loss_func(active, label[:, 0].view_as(\n",
    "                active)) + loss_func(consume, label[:, 1].view_as(consume))\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 计算平均损失\n",
    "        train_loss = sum(train_loss) / len(train_loss)\n",
    "            \n",
    "        # 每5个epoch打印一次损失\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "\n",
    "            # 打印损失和score\n",
    "            print('Epoch: {0}\\n Train loss: {1}'.format(epoch + 1, train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_step_train(graph_list, model, loss_func, optimizer, num_epochs, device, train_ratio, num_steps, threshold):\n",
    "\n",
    "    # 划分训练集和验证集\n",
    "    train_graph_list = graph_list[:int(len(graph_list) * train_ratio)]\n",
    "    val_graph_list = graph_list[int(len(graph_list) * train_ratio):]\n",
    "\n",
    "    # 将数据集放到device上\n",
    "    loss_func = loss_func.to(device)\n",
    "    train_graph_list = [graph.to(device) for graph in train_graph_list]\n",
    "    val_graph_list = [graph.to(device) for graph in val_graph_list]\n",
    "\n",
    "    print('train_length:', len(train_graph_list), 'val_length:', len(val_graph_list))\n",
    "\n",
    "    animator = Animator(xlabel='epoch', ylabel='loss & score', xlim=[0, num_epochs], ylim=[\n",
    "                        0, 50], legend=['train loss', 'val loss', 'score', 'best score'])\n",
    "\n",
    "    # 设置文件夹名称，以日和时分命名\n",
    "    dictionary_name = time.strftime(\"Day%d-Hour%H-Minutes%M\", time.localtime())\n",
    "    \n",
    "    # 如果文件夹不存在则创建文件夹\n",
    "    if not os.path.exists('model/' + dictionary_name):\n",
    "        os.mkdir('model/' + dictionary_name)  \n",
    "\n",
    "    model.train()\n",
    "\n",
    "    best_val_loss = 9999999999\n",
    "    best_score = 0\n",
    "    best_epoch = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    def data(pos):\n",
    "        # 返回从pos位置开始的长度为num_steps的序列\n",
    "        return train_graph_list[pos: pos + num_steps]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = []\n",
    "        \n",
    "        # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n",
    "        sequences = train_graph_list[random.randint(0, num_steps - 1):]\n",
    "        \n",
    "        num_subseqs = len(sequences) // num_steps\n",
    "        \n",
    "        # 长度为num_steps的子序列的起始索引\n",
    "        initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
    "        \n",
    "        # 在随机抽样的迭代过程中，\n",
    "        # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n",
    "        random.shuffle(initial_indices)\n",
    "        \n",
    "        X = [data(j) for j in initial_indices]\n",
    "        \n",
    "        for batch_graph in X:\n",
    "        \n",
    "            # 创建批处理图对象\n",
    "            batched_graph = dgl.batch(batch_graph)\n",
    "            \n",
    "            # 前向传播\n",
    "            active, consume = model(batched_graph)\n",
    "            \n",
    "            # 计算损失\n",
    "            label = batched_graph.ndata['label'].float()\n",
    "            loss = loss_func(active, label[:, 0].view_as(\n",
    "                active)) + loss_func(consume, label[:, 1].view_as(consume))\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 计算平均损失\n",
    "        train_loss = sum(train_loss) / len(train_loss)\n",
    "\n",
    "        # 使用评估函数计算验证集上的loss\n",
    "        val_loss = eval(train_graph_list, val_graph_list, model, loss_func, num_steps)\n",
    "\n",
    "        # 对val_loss开根号\n",
    "        sqrt_val_loss = torch.sqrt(torch.tensor(val_loss * 4))\n",
    "\n",
    "        # 计算score\n",
    "        score = 1 / (1 + sqrt_val_loss)\n",
    "\n",
    "        # 如果当前模型在验证集上的表现比之前所有模型都好，就保存当前模型的参数\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_score = score\n",
    "            best_epoch = epoch + 1\n",
    "            best_model_state = model.state_dict()\n",
    "            \n",
    "        # 每30个epoch打印一次损失和score\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "\n",
    "            # 打印损失和score\n",
    "            print('Epoch: {0}\\n Train loss: {1}\\n Val loss: {2}\\n Score: {3}\\n Best score: {4}\\n Best val loss: {5}\\n Best epoch: {6}'.format(\n",
    "                epoch + 1, train_loss, val_loss, score, best_score, best_val_loss, best_epoch))\n",
    "\n",
    "            # 绘制动画\n",
    "            animator.add(epoch + 1, (train_loss * 10, val_loss * 10, score * 100, best_score * 100))\n",
    "            \n",
    "        # 每30个epoch保存一次模型，并以epoch和该轮的score命名\n",
    "        if (epoch + 1) % 30 == 0 and score > threshold:\n",
    "            torch.save(model.state_dict(), 'model/' + dictionary_name + '/' + str(epoch + 1) + '-' + \"{:.3f}\".format(score))\n",
    "\n",
    "    return best_model_state, best_score, best_val_loss, best_epoch, dictionary_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_time_step_train(input_data, model, loss_func, optimizer, num_epochs, device, train_ratio, num_steps, batch_size, threshold):\n",
    "\n",
    "    # 划分训练集和验证集\n",
    "    train_data = input_data[:int(len(input_data) * train_ratio)]\n",
    "    val_data = input_data[int(len(input_data) * train_ratio):]\n",
    "    \n",
    "    # 将数据集转为tensor\n",
    "    train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "    val_data = torch.tensor(val_data, dtype=torch.float32)\n",
    "    \n",
    "    new_val_data = []\n",
    "    \n",
    "    for i in range(1, len(val_data)+1):\n",
    "        if i < num_steps:\n",
    "            new_val_data.append(torch.cat((train_data[-(num_steps - i):], val_data[:i]), dim=0))\n",
    "        else:\n",
    "            new_val_data.append(val_data[i - num_steps:i])\n",
    "        \n",
    "    val_data = torch.stack(new_val_data)\n",
    "\n",
    "    # 将数据集放到device上\n",
    "    loss_func = loss_func.to(device)\n",
    "    train_data = train_data.to(device)\n",
    "    val_data = val_data.to(device)\n",
    "\n",
    "    print('train_length:', len(train_data), 'val_length:', len(val_data))\n",
    "\n",
    "    animator = Animator(xlabel='epoch', ylabel='loss & score', xlim=[0, num_epochs], ylim=[\n",
    "                        0, 50], legend=['train loss', 'val loss', 'score', 'best score'])\n",
    "\n",
    "    # 设置文件夹名称，以日和时分命名\n",
    "    dictionary_name = time.strftime(\"Day%d-Hour%H-Minutes%M\", time.localtime())\n",
    "    \n",
    "    # 如果文件夹不存在则创建文件夹\n",
    "    if not os.path.exists('model/' + dictionary_name):\n",
    "        os.mkdir('model/' + dictionary_name)  \n",
    "\n",
    "    model.train()\n",
    "\n",
    "    best_val_loss = 9999999999\n",
    "    best_score = 0\n",
    "    best_epoch = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    def data(pos):\n",
    "        # 返回从pos位置开始的长度为num_steps的序列\n",
    "        return train_data[pos: pos + num_steps]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = []\n",
    "        \n",
    "        # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n",
    "        sequences = train_data[random.randint(0, num_steps - 1):]\n",
    "        \n",
    "        num_subseqs = len(sequences) // num_steps\n",
    "        \n",
    "        # 长度为num_steps的子序列的起始索引\n",
    "        initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n",
    "        \n",
    "        # 在随机抽样的迭代过程中，\n",
    "        # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n",
    "        random.shuffle(initial_indices)\n",
    "        \n",
    "        X = [data(j) for j in initial_indices]\n",
    "        \n",
    "        for sequences_data in X:\n",
    "            \n",
    "            for i in range(0, len(sequences_data), batch_size):\n",
    "                \n",
    "                batched_data = sequences_data[:, i:i+batch_size, :]\n",
    "                \n",
    "                # print('batched_data:', batched_data.shape)\n",
    "                \n",
    "                label = batched_data[-1, :, -2:]\n",
    "                \n",
    "                # print('label:', label.shape)\n",
    "                \n",
    "                # 前向传播\n",
    "                active, consume = model(batched_data)\n",
    "                \n",
    "                # print('active:', active.shape, 'consume:', consume.shape)\n",
    "                \n",
    "                # 计算损失\n",
    "                loss = loss_func(active, label[:, 0].view_as(\n",
    "                    active)) + loss_func(consume, label[:, 1].view_as(consume))\n",
    "                \n",
    "                train_loss.append(loss.item())\n",
    "                \n",
    "                # 反向传播\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # 计算平均损失\n",
    "        train_loss = sum(train_loss) / len(train_loss)\n",
    "\n",
    "        # 使用评估函数计算验证集上的loss\n",
    "        val_loss = cnn_eval(val_data, model, loss_func)\n",
    "\n",
    "        # 对val_loss开根号\n",
    "        sqrt_val_loss = torch.sqrt(torch.tensor(val_loss * 4))\n",
    "\n",
    "        # 计算score\n",
    "        score = 1 / (1 + sqrt_val_loss)\n",
    "\n",
    "        # 如果当前模型在验证集上的表现比之前所有模型都好，就保存当前模型的参数\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_score = score\n",
    "            best_epoch = epoch + 1\n",
    "            best_model_state = model.state_dict()\n",
    "            \n",
    "        # 每30个epoch打印一次损失和score\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "\n",
    "            # 打印损失和score\n",
    "            print('Epoch: {0}\\n Train loss: {1}\\n Val loss: {2}\\n Score: {3}\\n Best score: {4}\\n Best val loss: {5}\\n Best epoch: {6}'.format(\n",
    "                epoch + 1, train_loss, val_loss, score, best_score, best_val_loss, best_epoch))\n",
    "\n",
    "            # 绘制动画\n",
    "            animator.add(epoch + 1, (train_loss * 10, val_loss * 10, score * 100, best_score * 100))\n",
    "            \n",
    "        # 每30个epoch保存一次模型，并以epoch和该轮的score命名\n",
    "        if (epoch + 1) % 30 == 0 and score > threshold:\n",
    "            torch.save(model.state_dict(), 'model/' + dictionary_name + '/' + str(epoch + 1) + '-' + \"{:.3f}\".format(score))\n",
    "\n",
    "    return best_model_state, best_score, best_val_loss, best_epoch, dictionary_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(graph_list, model, device, predict_length):\n",
    "\n",
    "    # 将数据集放到device上\n",
    "    graph_list = [graph.to(device) for graph in graph_list]\n",
    "\n",
    "    # 预测\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # 创建批处理图对象\n",
    "        batched_graph = dgl.batch(graph_list)\n",
    "\n",
    "        # 前向传播\n",
    "        act_pre, con_pre = model(batched_graph)\n",
    "\n",
    "        # 将两个预测结果作为两列并输出为csv文件\n",
    "        predict = torch.cat((act_pre, con_pre), dim=1)\n",
    "        \n",
    "        # 保留前面的部分\n",
    "        pre_predict = predict[:-predict_length*1140]\n",
    "        \n",
    "        pre_output_unordered = pd.DataFrame(pre_predict.cpu().numpy())\n",
    "        pre_output_unordered.to_csv(\"prediction/pre_predict_unordered.csv\", index=False, header=False)\n",
    "        \n",
    "        pre_predictions = []\n",
    "        for i in range(1140):\n",
    "            for j in range(len(pre_predict)//1140):\n",
    "                pre_predictions.append([pre_predict[j*1140+i, 0], pre_predict[j*1140+i, 1]])\n",
    "                \n",
    "        pre_predictions_tensor = torch.tensor(pre_predictions)\n",
    "        pre_predictions_numpy = pre_predictions_tensor.detach().cpu().numpy()\n",
    "        \n",
    "        pre_output = pd.DataFrame(pre_predictions_numpy)\n",
    "        pre_output.to_csv(\"prediction/pre_predict_ordered.csv\", index=False, header=False)\n",
    "        \n",
    "        # 保留最后predict_length*1140行，即保留预测结果\n",
    "        predict = predict[-predict_length*1140:]\n",
    "\n",
    "        # 原结果是按照时间排列的，每天1140个节点，每个节点有两个预测值，所以需要将结果按照节点排列，使用for循环\n",
    "        predictions = []\n",
    "        for i in range(1140):\n",
    "            for j in range(predict_length):\n",
    "                predictions.append([predict[j*1140+i, 0], predict[j*1140+i, 1]])\n",
    "\n",
    "                \n",
    "        predictions_tensor = torch.tensor(predictions)\n",
    "        predictions_numpy = predictions_tensor.detach().cpu().numpy()\n",
    "\n",
    "        output = pd.DataFrame(predictions_numpy)\n",
    "        output.to_csv(\"prediction/predict.csv\", index=False, header=False)\n",
    "    return predictions_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_predict(graph_list, model_list, device, predict_length):\n",
    "    # 定义预测结果列表\n",
    "    multiple_predictions = []\n",
    "\n",
    "    # 预测\n",
    "    for model in model_list:\n",
    "        model.to(device)\n",
    "        predictions = predict(graph_list, model, device, predict_length)\n",
    "        multiple_predictions.append(predictions)\n",
    "\n",
    "    # 将多个模型的预测结果取平均\n",
    "    multiple_predictions = torch.stack(multiple_predictions)\n",
    "    predictions = torch.mean(multiple_predictions, dim=0)\n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "    \n",
    "    # 输出为csv文件\n",
    "    output = pd.DataFrame(predictions)\n",
    "    output.to_csv(\"prediction/predict.csv\", index=False, header=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_learning(graph_list, dictionary_name, min_threshold, max_threshold, device, predict_length):\n",
    "    # 集成学习，使用多个模型的预测结果的平均值作为最终的预测结果\n",
    "    # 从文件夹中读取模型\n",
    "    file_list = os.listdir(dictionary_name)\n",
    "    model_list = []\n",
    "    score_list = []\n",
    "    for file in file_list:\n",
    "        # 如果是文件夹则跳过\n",
    "        if os.path.isdir(dictionary_name + '/' + file):\n",
    "            continue\n",
    "        # 将文件名的后五位转为数字\n",
    "        score = float(file[-5:])\n",
    "        if score >= min_threshold and score <= max_threshold:\n",
    "            print('model_name:', file, 'score:', score)\n",
    "            model = new_model.GCN_LSTM()\n",
    "            model.load_state_dict(torch.load(dictionary_name + '/' + file))\n",
    "            model_list.append(model)\n",
    "            score_list.append(score)\n",
    "    print('model_num:', len(model_list))\n",
    "    print('pre_predict_length:', len(graph_list) - 4)\n",
    "    print('avg_score:', sum(score_list)/len(score_list))\n",
    "    multiple_predict(graph_list, model_list, device, predict_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 执行部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取dgl图训练集\n",
    "train_graph_list, _ = dgl.load_graphs('dgl_data/dgl_graphs_train.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取numpy数组训练集\n",
    "# train_data = np.load('numpy_data/train.npy')\n",
    "# print('train_data:', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数\n",
    "num_epochs = 2000\n",
    "train_ratio = 0.8\n",
    "learning_rate = 0.001\n",
    "loss_func = nn.MSELoss()\n",
    "threshold = 0.35\n",
    "time_step = 7\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = new_model.GCN_LSTM().to(device)\n",
    "# model = new_model.GCN_LSTM_test(time_step=time_step).to(device)\n",
    "# model = new_model.CNN(time_step=time_step).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模型\n",
    "# model = new_model.MLP_test()\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.load_state_dict(torch.load('model/new_model.MLP_test(1)_bs_0.486_bvl_0.279_be_4787_time_11_13_18_43.pth'))\n",
    "# model.to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer.load_state_dict(torch.load('model/new_model.MLP_test(1)_bs_0.486_bvl_0.279_be_4787_time_11_13_18_43.pth_optim'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_time_step_train_without_eval(train_graph_list, model, loss_func, optimizer, num_epochs, device, train_ratio, time_step, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_state, best_score, best_val_loss, best_epoch, dictionary_name = time_step_train(train_graph_list, model, loss_func, optimizer, num_epochs, device, train_ratio, time_step, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_state, best_score, best_val_loss, best_epoch, dictionary_name = new_time_step_train(train_graph_list, model, loss_func, optimizer, num_epochs, device, train_ratio, time_step, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_state, best_score, best_val_loss, best_epoch, dictionary_name = cnn_time_step_train(train_data, model, loss_func, optimizer, num_epochs, device, train_ratio, time_step, batch_size, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练结束后，使用最好的模型参数来创建最好的模型\n",
    "best_model = new_model.GCN_LSTM()\n",
    "best_model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取模型类名\n",
    "model_name = str(type(model))\n",
    "# 去除类名中的尖括号\n",
    "model_name = model_name[8:-2]\n",
    "# 转为3位小数的字符串\n",
    "best_score = \"{:.3f}\".format(best_score)\n",
    "best_epoch = str(best_epoch)\n",
    "\n",
    "torch.save(best_model.state_dict(), 'model/' + dictionary_name +'/best-' + best_epoch + '-' + best_score)\n",
    "torch.save(optimizer.state_dict(), 'model/' + dictionary_name +'/optimizer-0.000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取dgl图训练集\n",
    "train_graph_list, _ = dgl.load_graphs('dgl_data/dgl_graphs_train.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取dgl图测试集\n",
    "test_graph_list_A, _ = dgl.load_graphs('dgl_data/dgl_graphs_test_A.bin')\n",
    "test_graph_list_B, _ = dgl.load_graphs('dgl_data/dgl_graphs_test_B.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删去训练集中的label\n",
    "for graph in train_graph_list:\n",
    "    graph.ndata.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# 将训练集和测试集拼接起来\n",
    "graph_list = train_graph_list[-5:] + test_graph_list_A + test_graph_list_B\n",
    "print(len(graph_list))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 单一模型预测\n",
    "# 读取模型\n",
    "model = new_model.GCN_LSTM()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load('model/best_score_0.351_time_11_12_11_37.pth'))\n",
    "model.to(device)\n",
    "# 执行预测\n",
    "predict(graph_list, model, device, 3)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集成学习\n",
    "ensemble_learning(graph_list, 'model/Day24-Hour13-Minutes46', min_threshold=0.375, max_threshold=0.4, device=device,predict_length=4)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取pre_predict_unordered.csv文件中的预测结果\n",
    "pre_predict = pd.read_csv('prediction/pre_predict_unordered.csv', header=None)\n",
    "pre_predict_tensor = torch.tensor(pre_predict.values)\n",
    "# pre_predict_tensor = pre_predict_tensor.view(-1, 1140, 2)\n",
    "print(pre_predict_tensor.shape)\n",
    "\n",
    "train_graph_list, _ = dgl.load_graphs('dgl_data/dgl_graphs_train.bin')\n",
    "\n",
    "# 读取真实值\n",
    "batched_graph = dgl.batch(train_graph_list[-(len(graph_list)-4):])\n",
    "ture_label = batched_graph.ndata['label'].float()\n",
    "# ture_label = ture_label.view(-1, 1140, 2)\n",
    "print(ture_label.shape)\n",
    "\n",
    "# 计算loss\n",
    "loss_func = nn.MSELoss()\n",
    "loss = loss_func(pre_predict_tensor[:, 0], ture_label[:, 0].view_as(\n",
    "                pre_predict_tensor[:, 0])) + loss_func(pre_predict_tensor[:, 1], ture_label[:, 1].view_as(pre_predict_tensor[:, 1]))\n",
    "print('Loss:', loss.item())\n",
    "\n",
    "# 计算score\n",
    "sqrt_loss = torch.sqrt(loss * 4)\n",
    "score = 1 / (1 + sqrt_loss)\n",
    "print('Score:', score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df.shape:  (3420, 37)\n",
      "predict_df.shape:  (3420, 2)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 提取node_test_4_A.csv中的geohash_id和date_id，与prediction/predict.csv中的数据合并\n",
    "# 读取数据\n",
    "# test_df = pd.read_csv(\"data/node_test_4_A.csv\", encoding='utf-8')\n",
    "# predict_df = pd.read_csv(\"prediction/predict.csv\", encoding='utf-8', header=None)\n",
    "\n",
    "test_df = pd.read_csv(\"data/node_test_3_B.csv\", encoding='utf-8')\n",
    "predict_df = pd.read_csv(\"prediction/predict.csv\", encoding='utf-8', header=None)\n",
    "\n",
    "print(\"test_df.shape: \", test_df.shape)\n",
    "print(\"predict_df.shape: \", predict_df.shape)\n",
    "\n",
    "# 合并数据\n",
    "predict_df = pd.concat([test_df.iloc[:, 0], predict_df.iloc[:, 1], predict_df.iloc[:, 0], test_df.iloc[:, 1]], axis=1)\n",
    "\n",
    "# 添加列名\n",
    "predict_df.columns = [\"geohash_id\", \"consumption_level\", \"activity_level\", \"date_id\"] \n",
    "\n",
    "# 保存数据并以当前日期命名\n",
    "\n",
    "# 今日提交次数\n",
    "count = 1\n",
    "\n",
    "# 读取当前日期\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 保存数据\n",
    "predict_df.to_csv(\"submitCSV/submit_\" + now + \"_\" + str(count) +\".csv\", index=False, header=True)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 将文件中的所有逗号替换为tab\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 读取文件夹中的所有文件\n",
    "path = \"submitCSV/\"\n",
    "files = os.listdir(path)\n",
    "\n",
    "# 逐个文件进行处理\n",
    "for file in files:\n",
    "    # 读取文件\n",
    "    with open(path + file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "    # 替换所有逗号\n",
    "    data = re.sub(\",\", \"\\t\", data)\n",
    "    # 保存文件\n",
    "    with open(path + file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(data)\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
